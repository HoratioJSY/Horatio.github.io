<!DOCTYPE html>
<html lang="en">

<!-- Head tag -->
<head>

    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <!--Description-->
    
        <meta name="description" content="完全基于注意力机制，理解与训练翻译系统在本文中，我们根据谷歌的 Transformer 原论文与 Harvard NLP 所实现的代码学习构建了一个神经机器翻译系统。因此，我们希望各位读者也能根据这篇文章了解 Transformer 的架构，并动手实现一个神经机器翻译系统。
自 17 年 6 月份「">
    

    <!--Author-->
    
        <meta name="author" content="Horatio">
    

    <!--Open Graph Title-->
    
        <meta property="og:title" content="神经机器翻译"/>
    

    <!--Open Graph Site Name-->
    <meta property="og:site_name" content="Hello Autumn"/>

    <!--Page Cover-->
    
        <meta property="og:image" content=""/>
    

    <!-- Title -->
    
    <title>神经机器翻译 - Hello Autumn</title>

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/sass/main.css">

    <!--[if lt IE 8]>
        <script src="/js/ie/html5shiv.js"></script>
    <![endif]-->

    <!--[if lt IE 8]>
        <link rel="stylesheet" href="/sass/ie8.css">
    <![endif]-->

    <!--[if lt IE 9]>
        <link rel="stylesheet" href="/sass/ie9.css">
    <![endif]-->

    <!-- Gallery -->
    <link href="//cdn.rawgit.com/noelboss/featherlight/1.3.5/release/featherlight.min.css" type="text/css" rel="stylesheet" />

    <!-- Google Analytics -->
    


<link rel="shortcut icon" href="http://p598yuf6e.bkt.clouddn.com/favicon.ico" type="image/x-icon"/>
<link rel="icon" href="http://p598yuf6e.bkt.clouddn.com/favicon.ico" type="image/x-icon"/>
<link rel="apple-touch-icon" href="http://p598yuf6e.bkt.clouddn.com/favicon.ico"><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body>

    <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="wrapper">

        <!-- Menu -->
        <!-- Header -->
<header id="header">
    <div class="inner">

        <!-- Logo -->
        <a href="/" class="logo">
            <span class="symbol"><img src="http://p598yuf6e.bkt.clouddn.com/BrainIcon.png" alt="" /></span><span class="title">Hello Autumn</span>
        </a>

        <!-- Nav -->
        <nav>
            <ul>
                <li><a href="#menu">Menu</a></li>
            </ul>
        </nav>

    </div>
</header>

<!-- Menu -->
<nav id="menu">
    <h2>Menu</h2>
    <ul>
        
            <li>
                <a href="/me/">Me</a>
            </li>
        
            <li>
                <a href="/">Photographer</a>
            </li>
        
            <li>
                <a href="/archives">Archives</a>
            </li>
        
            <li>
                <a href="/">About</a>
            </li>
        
    </ul>
</nav>


        <div id="main">
            <div class="inner">

                <!-- Main Content -->
                

    <h1>神经机器翻译</h1>



<!-- Gallery -->


<!-- Content -->
<h2 id="完全基于注意力机制，理解与训练翻译系统"><a href="#完全基于注意力机制，理解与训练翻译系统" class="headerlink" title="完全基于注意力机制，理解与训练翻译系统"></a>完全基于注意力机制，理解与训练翻译系统</h2><p>在本文中，我们根据谷歌的 Transformer 原论文与 Harvard NLP 所实现的代码学习构建了一个神经机器翻译系统。因此，我们希望各位读者也能根据这篇文章了解 Transformer 的架构，并动手实现一个神经机器翻译系统。</p>
<p>自 17 年 6 月份「Attention is All You Need」发表以来，Transformer 受到越来越多的关注。它除了能显著提升翻译质量，同时还为很多 NLP 任务提供了新的架构。这篇论文放弃了传统基于 RNN 或 CNN 的深度架构，并只保留了注意力（Attentaion）机制，虽然原论文在这一方面描述地比较清楚，但要正确地实现这样的新型架构可能非常困难。</p>
<p>在这篇文章中，我们从注意力机制到神经机器翻译系统解释了实现 Transformer 的架构与代码，并借助这些实现理解原论文。机器之心整理了整个实现，并根据我们对原论文与实现的理解添加一些解释。整个文章就是一个可运行的 Jupyter Notebook，读者可直接在 Colaboratory 中阅读文章与运行代码。</p>
<ul>
<li>原实现地址：<a href="https://github.com/harvardnlp/annotated-transformer" target="_blank" rel="noopener">https://github.com/harvardnlp/annotated-transformer</a></li>
</ul>
<p>本文所有的代码都可以在谷歌 Colab 上运行，且读者也可以在 GitHub 中下载全部的代码在本地运行。这篇文章非常适合于研究者与感兴趣的开发者，代码很大程度上都依赖于 OpenNMT 库。</p>
<p>在运行模型前，我们需要确保有对应的环境。如果在本地运行，那么需要确保以下基本库的导入不会报错，若在 Colab 上运行，那么首先需要运行以下第一个 pip 语句安装对应的包。Colab 的环境配置非常简单，一般只需要使用 conda 或 pip 命令就能完成。此外，Colab 语句前面加上「!」表示这是命令行，而不加感叹号则表示这个代码框是 Python 代码。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># !pip install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl numpy matplotlib spacy torchtext seaborn </span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> math, copy, time</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn</span><br><span class="line">seaborn.set_context(context=<span class="string">"talk"</span>)</span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure>
<h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><p>减少序列计算的任务目标构成了 Extended Neural GPU、ByteNet 和 ConvS2S 的基础，它们都是使用卷积神经网络作为基本构建块，因而能对所有输入与输出位置的隐藏表征执行并行计算。在这些模型中，两个任意输入与输出位置的信号关联所需要的运算数量与它们的位置距离成正比，对于 ConvS2S 为线性增长，对于 ByteNet 为对数增长。这种现象使得学习较远位置的依赖关系非常困难。而在 Transformer 中，这种成本会减少到一个固定的运算数量，尽管平均注意力位置加权会减少有效表征力，但使用 Multi-Head Attention 注意力机制可以抵消这种成本。</p>
<p>自注意力（Self-attention），有时也称为内部注意力，它是一种涉及单序列不同位置的注意力机制，并能计算序列的表征。自注意力在多种任务中都有非常成功的应用，例如阅读理解、摘要概括、文字蕴含和语句表征等。自注意力这种在序列内部执行 Attention 的方法可以视为搜索序列内部的隐藏关系，这种内部关系对于翻译以及序列任务的性能非常重要。</p>
<p>然而就我们所知道的，Transformer 是第一种完全依赖于自注意力以计算输入与输出表征的方法，这意味着它没有使用序列对齐的 RNN 或卷积网络。从 Transformer 的结构就可以看出，它并没有使用深度网络抽取序列特征，顶多使用几个线性变换对特征进行变换。</p>
<p>本文主要从模型架构、训练配置和两个实际翻译模型开始介绍 Ashish Vaswani 等人的原论文与 Harvard NLP 团队实现的代码。在模型架构中，我们将讨论编码器、解码器、注意力机制以及位置编码等关键组成部分，而训练配置将讨论如何抽取批量数据、设定训练循环、选择最优化方法和正则化器等。最后我们将跟随 Alexander Rush 等人的实现训练两个神经机器翻译系统，其中一个仅使用简单的合成数据，而另一个则是真实的 IWSLT 德语-英语翻译数据集。</p>
<h3 id="模型架构"><a href="#模型架构" class="headerlink" title="模型架构"></a>模型架构</h3><p>大多数神经序列模型都使用编码器-解码器框架，其中编码器将表征符号的输入序列 $(x_1, …, x_n)$ 映射到连续表征 $z=(z_1, …, z_n)$。给定中间变量 z，解码器将会生成一个输出序列 $(y_1,…,y_m)$。在每一个时间步上，模型都是自回归的（auto-regressive），当生成序列中的下一个元素时，先前生成的元素会作为输入。</p>
<p>以下展示了一个标准的编码器-解码器框架，EncoderDecoder 类定义了先编码后解码的过程，例如先将英文序列编码为一个隐向量，在基于这个中间表征解码为中文序列。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">EncoderDecoder</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line"> <span class="string">"""</span></span><br><span class="line"><span class="string"> A standard Encoder-Decoder architecture. Base for this and many </span></span><br><span class="line"><span class="string"> other models.</span></span><br><span class="line"><span class="string"> """</span></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, encoder, decoder, src_embed, tgt_embed, generator)</span>:</span></span><br><span class="line"> super(EncoderDecoder, self).__init__()</span><br><span class="line"> self.encoder = encoder</span><br><span class="line"> self.decoder = decoder</span><br><span class="line"> self.src_embed = src_embed</span><br><span class="line"> self.tgt_embed = tgt_embed</span><br><span class="line"> self.generator = generator</span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, src, tgt, src_mask, tgt_mask)</span>:</span></span><br><span class="line"> <span class="string">"Take in and process masked src and target sequences."</span></span><br><span class="line"> <span class="keyword">return</span> self.decode(self.encode(src, src_mask), src_mask,</span><br><span class="line"> tgt, tgt_mask)</span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">encode</span><span class="params">(self, src, src_mask)</span>:</span></span><br><span class="line"> <span class="keyword">return</span> self.encoder(self.src_embed(src), src_mask)</span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">decode</span><span class="params">(self, memory, src_mask, tgt, tgt_mask)</span>:</span></span><br><span class="line"> <span class="keyword">return</span> self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Generator</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line"> <span class="string">"Define standard linear + softmax generation step."</span></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, d_model, vocab)</span>:</span></span><br><span class="line"> super(Generator, self).__init__()</span><br><span class="line"> self.proj = nn.Linear(d_model, vocab)</span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line"> <span class="keyword">return</span> F.log_softmax(self.proj(x), dim=<span class="number">-1</span>)</span><br></pre></td></tr></table></figure>
<p>Transformer 的整体架构也采用了这种编码器-解码器的框架，它使用了多层自注意力机制和层级归一化，编码器和解码器都会使用全连接层和残差连接。Transformer 的整体结构如下图所示：</p>
<div align="center"><img src="http://p598yuf6e.bkt.clouddn.com//transformer/image.png" style="zoom:70%"></div>

<p>如上所示，左侧为输入序列的编码器。输入序列首先会转换为词嵌入向量，在与位置编码向量相加后可作为 Multi-Head Attention 模块的输入，该模块的输出在与输入相加后将投入层级归一化函数，得出的输出在馈送到全连接层后可得出编码器模块的输出。这样相同的 6 个编码器模块（N=6）可构成整个编码器架构。解码器模块首先同样构建了一个自注意力模块，然后再结合编码器的输出实现 Multi-Head Attention，最后投入全连接网络并输出预测词概率。</p>
<p>这里只是简单地介绍了模型的大概过程，很多如位置编码、Multi-Head Attention 模块、层级归一化、残差链接和逐位置前馈网络等概念都需要读者详细阅读下文，最后再回过头理解完整的过程。</p>
<h4 id="编码器"><a href="#编码器" class="headerlink" title="编码器"></a>编码器</h4><p>编码器由相同的 6 个模块堆叠而成，每一个模块都有两个子层级构成。其中第一个子层级是 Multi-Head 自注意机制，其中自注意力表示输入和输出序列都是同一条。第二个子层级采用了全连接网络，主要作用在于注意子层级的特征。此外，每一个子层级都会添加一个残差连接和层级归一化。</p>
<p>以下定义了编码器的主体框架，在 Encoder 类中，每一个 layer 表示一个编码器模块，这个编码器模块由两个子层级组成。layer 函数的输出表示经过层级归一化的编码器模块输出，通过 For 循环堆叠层级就能完成整个编码器的构建。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">clones</span><span class="params">(module, N)</span>:</span></span><br><span class="line"> <span class="string">"Produce N identical layers."</span></span><br><span class="line"> <span class="keyword">return</span> nn.ModuleList([copy.deepcopy(module) <span class="keyword">for</span> _ <span class="keyword">in</span> range(N)])</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Encoder</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line"> <span class="string">"Core encoder is a stack of N layers"</span></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, layer, N)</span>:</span></span><br><span class="line"> super(Encoder, self).__init__()</span><br><span class="line"> self.layers = clones(layer, N)</span><br><span class="line"> self.norm = LayerNorm(layer.size)</span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, mask)</span>:</span></span><br><span class="line"> <span class="string">"Pass the input (and mask) through each layer in turn."</span></span><br><span class="line"> <span class="keyword">for</span> layer <span class="keyword">in</span> self.layers:</span><br><span class="line"> x = layer(x, mask)</span><br><span class="line"> <span class="keyword">return</span> self.norm(x)</span><br></pre></td></tr></table></figure>
<p>如编码器的结构图所示，每个子层级都会会添加一个残差连接，并随后传入层级归一化。上面构建的主体架构也调用了层级归一化函数，以下代码展示了层级归一化的定义。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LayerNorm</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line"> <span class="string">"Construct a layernorm module (See citation for details)."</span></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, features, eps=<span class="number">1e-6</span>)</span>:</span></span><br><span class="line"> super(LayerNorm, self).__init__()</span><br><span class="line"> self.a_2 = nn.Parameter(torch.ones(features))</span><br><span class="line"> self.b_2 = nn.Parameter(torch.zeros(features))</span><br><span class="line"> self.eps = eps</span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line"> mean = x.mean(<span class="number">-1</span>, keepdim=<span class="keyword">True</span>)</span><br><span class="line"> std = x.std(<span class="number">-1</span>, keepdim=<span class="keyword">True</span>)</span><br><span class="line"> <span class="keyword">return</span> self.a_2 * (x - mean) / (std + self.eps) + self.b_2</span><br></pre></td></tr></table></figure>
<p>层级归一化可以通过修正每一层内激活值的均值与方差而大大减少协方差偏离问题。简单来说，一个层级的均值可以通过计算该层所有神经元激活值的平均值而得出，然后再根据均值计算该层所有神经元激活值的方差。最后根据均值与方差，我们可以对这一层所有输出值进行归一化。</p>
<p>如上 LayerNorm 类所示，我们首先需要使用方法 mean 求输入 x 最后一个维度的均值，keepdim 为真表示求均值后的维度保持不变，并且均值会广播操作到对应的维度。同样使用 std 方法计算标准差后，该层所有激活值分别减去均值再除以标准差就能实现归一化，分母加上一个小值 eps 可以防止分母为零。</p>
<p>因此，每一个子层的输出为 LayerNorm(x+Sublayer(x))，其中 Sublayer(x) 表示由子层本身实现的函数。我们应用 Dropout 将每一个子层的输出随机失活，这一过程会在加上子层输入和执行归一化之前完成。</p>
<p>以下定义了残差连接，我们会在投入层级归一化函数前将子层级的输入与输出相加。为了使用这些残差连接，模型中所有的子层和嵌入层的输出维度都是 d_model=512。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SublayerConnection</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line"> <span class="string">"""</span></span><br><span class="line"><span class="string"> A residual connection followed by a layer norm.</span></span><br><span class="line"><span class="string"> Note for code simplicity the norm is first as opposed to last.</span></span><br><span class="line"><span class="string"> """</span></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, size, dropout)</span>:</span></span><br><span class="line"> super(SublayerConnection, self).__init__()</span><br><span class="line"> self.norm = LayerNorm(size)</span><br><span class="line"> self.dropout = nn.Dropout(dropout)</span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, sublayer)</span>:</span></span><br><span class="line"> <span class="string">"Apply residual connection to any sublayer with the same size."</span></span><br><span class="line"> <span class="keyword">return</span> x + self.dropout(sublayer(self.norm(x)))</span><br></pre></td></tr></table></figure>
<p>在上述代码定义中，x 表示上一层添加了残差连接的输出，这一层添加了残差连接的输出需要将 x 执行层级归一化，然后馈送到 Multi-Head Attention 层或全连接层，添加 Dropout 操作后可作为这一子层级的输出。最后将该子层的输出向量与输入向量相加得到下一层的输入。</p>
<p>编码器每个模块有两个子层，第一个为 multi-head 自注意力层，第二个为简单的逐位置全连接前馈网络。以下的 EncoderLayer 类定义了一个编码器模块的过程。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">EncoderLayer</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line"> <span class="string">"Encoder is made up of self-attn and feed forward (defined below)"</span></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, size, self_attn, feed_forward, dropout)</span>:</span></span><br><span class="line"> super(EncoderLayer, self).__init__()</span><br><span class="line"> self.self_attn = self_attn</span><br><span class="line"> self.feed_forward = feed_forward</span><br><span class="line"> self.sublayer = clones(SublayerConnection(size, dropout), <span class="number">2</span>)</span><br><span class="line"> self.size = size</span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, mask)</span>:</span></span><br><span class="line"> <span class="string">"Follow Figure 1 (left) for connections."</span></span><br><span class="line"> x = self.sublayer[<span class="number">0</span>](x, <span class="keyword">lambda</span> x: self.self_attn(x, x, x, mask))</span><br><span class="line"> <span class="keyword">return</span> self.sublayer[<span class="number">1</span>](x, self.feed_forward)</span><br></pre></td></tr></table></figure>
<p>以上代码叠加了自注意力层与全连接层，其中 Multi-Head Attention 机制的输入 Query、Key 和 Value 都为 x 就表示自注意力。</p>
<h4 id="解码器"><a href="#解码器" class="headerlink" title="解码器"></a>解码器</h4><p>解码器也由相同的 6 个模块堆叠而成，每一个解码器模块都有三个子层组成，每一个子层同样会加上残差连接与层级归一化运算。第一个和第三个子层分别与编码器的 Multi-Head 自注意力层和全连接层相同，而第二个子层所采用的 Multi-Head Attention 机制使用编码器的输出作为 Key 和 Value，采用解码模块第一个子层的输出作为 Query。</p>
<p>我们同样需要修正编码器堆栈中的自注意力子层，以防止当前位置注意到后续序列位置，这一修正可通过掩码实现。以下的解码器的主体堆叠结构和编码器相似，只需要简单地堆叠解码器模块就能完成。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Decoder</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line"> <span class="string">"Generic N layer decoder with masking."</span></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, layer, N)</span>:</span></span><br><span class="line"> super(Decoder, self).__init__()</span><br><span class="line"> self.layers = clones(layer, N)</span><br><span class="line"> self.norm = LayerNorm(layer.size)</span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, memory, src_mask, tgt_mask)</span>:</span></span><br><span class="line"> <span class="keyword">for</span> layer <span class="keyword">in</span> self.layers:</span><br><span class="line"> x = layer(x, memory, src_mask, tgt_mask)</span><br><span class="line"> <span class="keyword">return</span> self.norm(x)</span><br></pre></td></tr></table></figure>
<p>以下展示了一个解码器模块的架构，第一个 Multi-Head Attention 机制的三个输入都是 x，因此它是自注意力。第二个 Multi-Head 注意力机制输入的 Key 和 Value 是编码器的输出 memory，输入的 Query 是上一个子层的输出 x。最后在叠加一个全连接网络以完成一个编码器模块的构建。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DecoderLayer</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line"> <span class="string">"Decoder is made of self-attn, src-attn, and feed forward (defined below)"</span></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, size, self_attn, src_attn, feed_forward, dropout)</span>:</span></span><br><span class="line"> super(DecoderLayer, self).__init__()</span><br><span class="line"> self.size = size</span><br><span class="line"> self.self_attn = self_attn</span><br><span class="line"> self.src_attn = src_attn</span><br><span class="line"> self.feed_forward = feed_forward</span><br><span class="line"> self.sublayer = clones(SublayerConnection(size, dropout), <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, memory, src_mask, tgt_mask)</span>:</span></span><br><span class="line"> <span class="string">"Follow Figure 1 (right) for connections."</span></span><br><span class="line"> m = memory</span><br><span class="line"> x = self.sublayer[<span class="number">0</span>](x, <span class="keyword">lambda</span> x: self.self_attn(x, x, x, tgt_mask))</span><br><span class="line"> x = self.sublayer[<span class="number">1</span>](x, <span class="keyword">lambda</span> x: self.src_attn(x, m, m, src_mask))</span><br><span class="line"> <span class="keyword">return</span> self.sublayer[<span class="number">2</span>](x, self.feed_forward)</span><br></pre></td></tr></table></figure>
<p>对于序列建模来说，模型应该只能查看有限的序列信息。例如在时间步 i，模型能读取整个输入序列，但只能查看时间步 i 及之前的序列信息。对于 Transformer 的解码器来说，它会输入整个目标序列，且注意力机制会注意到整个目标序列各个位置的信息，因此我们需要限制注意力机制能看到的信息。</p>
<p>如上所述，Transformer 在注意力机制中使用 subsequent_mask 函数以避免当前位置注意到后面位置的信息。因为输出词嵌入是位置的一个偏移，因此我们可以确保位置 i 的预测仅取决于在位置 i 之前的已知输出。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">subsequent_mask</span><span class="params">(size)</span>:</span></span><br><span class="line"> <span class="string">"Mask out subsequent positions."</span></span><br><span class="line"> attn_shape = (<span class="number">1</span>, size, size)</span><br><span class="line"> subsequent_mask = np.triu(np.ones(attn_shape), k=<span class="number">1</span>).astype(<span class="string">'uint8'</span>)</span><br><span class="line"> <span class="keyword">return</span> torch.from_numpy(subsequent_mask) == <span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>以下为注意力掩码的可视化，其中每一行为一个词，每一列则表示一个位置。下图展示了每一个词允许查看的位置，训练中词是不能注意到未来词的。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">5</span>,<span class="number">5</span>))</span><br><span class="line">plt.imshow(subsequent_mask(<span class="number">20</span>)[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<div align="center"><img src="http://p598yuf6e.bkt.clouddn.com//transformer/image1.png" style="zoom:50%"></div>

<h4 id="注意力机制"><a href="#注意力机制" class="headerlink" title="注意力机制"></a>注意力机制</h4><p>谷歌在原论文中展示了注意力机制的一般化定义，即它和 RNN 或 CNN 一样也是一种编码序列的方案。一个注意力函数可以描述为将 Query 与一组键值对（Key-Value）映射到输出，其中 Query、Key、Value 和输出都是向量。输出可以通过值的加权和而计算得出，其中分配到每一个值的权重可通过 Query 和对应 Key 的适应度函数（compatibility function）计算。</p>
<p>在翻译任务中，Query 可以视为原语词向量序列，而 Key 和 Value 可以视为目标语词向量序列。一般的注意力机制可解释为计算 Query 和 Key 之间的相似性，并利用这种相似性确定 Query 和 Value 之间的注意力关系。</p>
<p>以下是点积注意力的结构示意图，我们称这种特殊的结构为「缩放点积注意力」。它的输入由维度是 d_k 的 Query 和 Key 组成，Value 的维度是 d_v。如下所示，我们会先计算 Query 和所有 Key 的点乘，并每一个都除上 squre_root(d_k) 以防止乘积结果过大，然后再馈送到 Softmax 函数以获得与 Value 对应的权重。根据这样的权重，我们就可以配置 Value 向量而得出最后的输出。</p>
<div align="center"><img src="http://p598yuf6e.bkt.clouddn.com//transformer/image2.png" style="zoom:70%"></div>

<p>在上图中，Q 和 K 的运算有一个可选的 Mask 过程。在编码器中，我们不需要使用它限制注意力模块所关注的序列信息。而在解码器中，我们需要它限制注意力模块只能注意到当前时间步及之前时间步的信息。这一个过程可以很简洁地表示为函数 Attention(Q, K, V)。</p>
<p>Attention(Q, K, V) 函数在输入矩阵 Q、K 和 V 的情况下可计算 Query 序列与 Value 序列之间的注意力关系。其中 Q 的维度为 n×d_k，表示有 n 条维度为 d_k 的 Query、K 的维度为 m×d_k、V 的维度为 m×d_v。这三个矩阵的乘积可得出 n×d_v 维的矩阵，它表示 n 条 Query 对应注意到的 Value 向量。</p>
<p>$ \text { Attention } ( Q , K , V ) = \operatorname { softmax } \left( \frac { Q K ^ { T } } { \sqrt { d _ { k } } } \right) V $</p>
<p>上式中 Q 与 K 的点积会除上 $\sqrt{d_k}$ 以实现缩放。原论文作者发现，当每一条 Query 的维度 $d_k$ 比较小时，点乘注意力和加性注意力的性能相似，但随着 $d_k$ 的增大，加性注意力的性能会超过点乘注意力机制。不过点乘注意力有一个强大的属性，即它可以利用矩阵乘法的并行运算大大加快训练速度。</p>
<p>原论文作者认为点乘注意力效果不好的原因是在 $d_k$ 比较大的情况下，乘积结果会非常大，因此会导致 Softmax 快速饱和并只能提供非常小的梯度来更新参数。所以他们采用了 $\sqrt{d_k}$ 来缩小点乘结果，并防止 Softmax 函数饱和。</p>
<p>为了证明为什么点积的量级会变得很大，我们假设元素 q 和 k 都是均值为 0、方差为 1 的独立随机变量，它们的点乘 $q\star k=∑q_i\star k_i$ 有 0 均值和 $d_k$ 的方差。为了抵消这种影响，我们可以通过除上 $\sqrt{d_k}$  归一化点乘结果。</p>
<p>以下函数定义了一个标准的点乘注意力，该函数最终会返回匹配 Query 和 Key 的权重或概率 p_attn​，以及最终注意力机制的输出序列。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">attention</span><span class="params">(query, key, value, mask=None, dropout=None)</span>:</span></span><br><span class="line"> <span class="string">"Compute 'Scaled Dot Product Attention'"</span></span><br><span class="line"> d_k = query.size(<span class="number">-1</span>)</span><br><span class="line"> scores = torch.matmul(query, key.transpose(<span class="number">-2</span>, <span class="number">-1</span>)) \</span><br><span class="line"> / math.sqrt(d_k)</span><br><span class="line"> <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line"> scores = scores.masked_fill(mask == <span class="number">0</span>, <span class="number">-1e9</span>)</span><br><span class="line"> p_attn = F.softmax(scores, dim = <span class="number">-1</span>)</span><br><span class="line"> <span class="keyword">if</span> dropout <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line"> p_attn = dropout(p_attn)</span><br><span class="line"> <span class="keyword">return</span> torch.matmul(p_attn, value), p_attn</span><br></pre></td></tr></table></figure>
<p>在上述函数中，query 矩阵的列数即维度数 d_k。在计算点乘并缩放后，我们可以在最后一个维度执行 Softmax 函数以得到概率 p_attn。</p>
<p>两个最常见的注意力函数是加性注意力（additive attention）和点乘（乘法）注意力。除了要除上缩放因子 squre_root(d_k)，标准的点乘注意力与原论文中所采用的是相同的。加性注意力会使用单隐藏层的前馈网络计算适应度函数，它们在理论复杂度上是相似的。点积注意力在实践中更快速且参数空间更高效，因为它能通过高度优化的矩阵乘法库并行地计算。</p>
<h4 id="Multi-head-Attention"><a href="#Multi-head-Attention" class="headerlink" title="Multi-head Attention"></a>Multi-head Attention</h4><p>下图展示了 Transformer 中所采用的 Multi-head Attention 结构，它其实就是多个点乘注意力并行地处理并最后将结果拼接在一起。一般而言，我们可以对三个输入矩阵 Q、V、K 分别进行 h 个不同的线性变换，然后分别将它们投入 h 个点乘注意力函数并拼接所有的输出结果。</p>
<div align="center"><img src="http://p598yuf6e.bkt.clouddn.com//transformer/image3.png" style="zoom:60%"></div>

<p>Multi-head Attention 允许模型联合关注不同位置的不同表征子空间信息，我们可以理解为在参数不共享的情况下，多次执行点乘注意力。Multi-head Attention 的表达如下所示：</p>
<p>$ \text { MultiHead } ( Q , K , V ) = \operatorname { Concat } \left( \text { head } _ {1} , \dots , \text { head } _ { h } \right) W ^ { O } $</p>
<p>$ \text { where head}_i = \text { Attention } \left( Q W _ { i } ^ { Q } , K W _ { i } ^ { K } , V W _ { i } ^ { V } \right) $</p>
<p>其中 W 为对应线性变换的权重矩阵，Attention() 就是上文所实现的点乘注意力函数。</p>
<p>在原论文和实现中，研究者使用了 h=8 个并行点乘注意力层而完成 Multi-head Attention。对于每一个注意力层，原论文使用的维度是 d_k=d_v=d_model/h=64。由于每一个并行注意力层的维度降低，总的计算成本和单个点乘注意力在全维度上的成本非常相近。</p>
<p>以下定义了 Multi-head Attention 模块，它实现了上图所示的结构：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MultiHeadedAttention</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, h, d_model, dropout=<span class="number">0.1</span>)</span>:</span></span><br><span class="line"> <span class="string">"Take in model size and number of heads."</span></span><br><span class="line"> super(MultiHeadedAttention, self).__init__()</span><br><span class="line"> <span class="keyword">assert</span> d_model % h == <span class="number">0</span></span><br><span class="line"> <span class="comment"># We assume d_v always equals d_k</span></span><br><span class="line"> self.d_k = d_model // h</span><br><span class="line"> self.h = h</span><br><span class="line"> self.linears = clones(nn.Linear(d_model, d_model), <span class="number">4</span>)</span><br><span class="line"> self.attn = <span class="keyword">None</span></span><br><span class="line"> self.dropout = nn.Dropout(p=dropout)</span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, query, key, value, mask=None)</span>:</span></span><br><span class="line"> <span class="string">"Implements Figure 2"</span></span><br><span class="line"> <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line"> <span class="comment"># Same mask applied to all h heads.</span></span><br><span class="line"> mask = mask.unsqueeze(<span class="number">1</span>)</span><br><span class="line"> nbatches = query.size(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"> <span class="comment"># 1) Do all the linear projections in batch from d_model =&gt; h x d_k </span></span><br><span class="line"> query, key, value = \</span><br><span class="line"> [l(x).view(nbatches, <span class="number">-1</span>, self.h, self.d_k).transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"> <span class="keyword">for</span> l, x <span class="keyword">in</span> zip(self.linears, (query, key, value))]</span><br><span class="line"></span><br><span class="line"> <span class="comment"># 2) Apply attention on all the projected vectors in batch. </span></span><br><span class="line"> x, self.attn = attention(query, key, value, mask=mask, </span><br><span class="line"> dropout=self.dropout)</span><br><span class="line"></span><br><span class="line"> <span class="comment"># 3) "Concat" using a view and apply a final linear. </span></span><br><span class="line"> x = x.transpose(<span class="number">1</span>, <span class="number">2</span>).contiguous() \</span><br><span class="line"> .view(nbatches, <span class="number">-1</span>, self.h * self.d_k)</span><br><span class="line"> <span class="keyword">return</span> self.linears[<span class="number">-1</span>](x)</span><br></pre></td></tr></table></figure>
<p>在以上代码中，首先我们会取 query 的第一个维度作为批量样本数，然后再实现多个线性变换将 d_model 维的词嵌入向量压缩到 d_k 维的隐藏向量，变换后的矩阵将作为点乘注意力的输入。点乘注意力输出的矩阵将在最后一个维度拼接，即 8 个 n×64 维的矩阵拼接为 n×512 维的大矩阵，其中 n 为批量数。这样我们就将输出向量恢复为与词嵌入向量相等的维度。</p>
<p>前面我们已经了解到 Transformer 使用了大量的自注意力机制，即 Attention(X, X, X )。简单而言，Transformer 使用自注意力代替 RNN 或 CNN 抽取序列特征。对于机器翻译任务而言，自注意力输入的 Query、Key 和 Value 都是相同的矩阵，那么 Query 和 Key 之间的运算就相当于计算输入序列内部的相似性，并根据这种相似性或权重注意到序列自身（Value）的内部联系。</p>
<p>这种内部联系可能是主语注意到谓语和宾语的信息或其它隐藏在句子内部的结构。Transformer 在神经机器翻译和阅读理解等任务上的优秀性能，都证明序列内部结构的重要性。</p>
<p>Transformer 以三种不同的方式使用 multi-head Attention。首先在编码器到解码器的层级中，Query 来源于前面解码器的输出，而记忆的 Key 与 Value 都来自编码器的输出。这允许解码器中的每一个位置都注意输入序列中的所有位置，因此它实际上模仿了序列到序列模型中典型的编码器-解码器注意力机制。</p>
<p>其次，编码器包含了自注意力层，且该层中的所有 Value、Key 和 Query 都是相同的输入矩阵，即编码器的前层输出。最后，解码器中的自注意力层允许解码器中的每一个位置都注意到包括当前位置的所有合法位置。这可以通过上文定义的 Mask 函数实现，从而防止产生左向信息流来保持自回归属性。</p>
<h4 id="逐位置的前馈网络"><a href="#逐位置的前馈网络" class="headerlink" title="逐位置的前馈网络"></a>逐位置的前馈网络</h4><p>为了注意子层，每一个编码器和解码器模块最后都包含一个全连接前馈网络，它独立且相同地应用于每一个位置。这个前馈网络包含两个线性变换和一个非线性激活函数，且在训练过程中我们可以在两层网络之间添加 Dropout 方法：</p>
<p>$ \text { FFN } ( x ) = \max \left( 0 , x W _ { 1 } + b _ { 1 } \right) W _ { 2 } + b _ { 2 } $</p>
<p>如果我们将这两个全连接层级与残差连接和层级归一化结合，那么它就是每一个编码器与解码器模块最后所必须的子层。我们可以将这一子层表示为：$LayerNorm(x + max(0, x\star w_1 + b_1)w_2 + b_2)$。</p>
<p>尽管线性变换在所有不同的位置上都相同，但在不同的层级中使用不同的参数，这种变换其实同样可以描述为核大小为 1 的两个卷积。输入和输出的维度 d_model=512，而内部层级的维度 d_ff=2018。</p>
<p>如下所示，前馈网络的定义和常规的方法并没有什么区别，不过这个网络没有添加偏置项，且对第一个全连接的输出实现了 Dropout 以防止过拟合。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PositionwiseFeedForward</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line"> <span class="string">"Implements FFN equation."</span></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, d_model, d_ff, dropout=<span class="number">0.1</span>)</span>:</span></span><br><span class="line"> super(PositionwiseFeedForward, self).__init__()</span><br><span class="line"> self.w_1 = nn.Linear(d_model, d_ff)</span><br><span class="line"> self.w_2 = nn.Linear(d_ff, d_model)</span><br><span class="line"> self.dropout = nn.Dropout(dropout)</span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line"> <span class="keyword">return</span> self.w_2(self.dropout(F.relu(self.w_1(x))))</span><br></pre></td></tr></table></figure>
<h4 id="词嵌入和-Softmax"><a href="#词嵌入和-Softmax" class="headerlink" title="词嵌入和 Softmax"></a>词嵌入和 Softmax</h4><p>与其它序列模型相似，我们可以使用学得的词嵌入将输入和输出的词汇转换为维度等于 d_model 的向量。我们还可以使用一般的线性变换和 Softmax 函数将解码器的输出转化为预测下一个词汇的概率。在愿论文的模型中，两个嵌入层和 pre-softmax 线性变换的权重矩阵是共享的。在词嵌入层中，我们将所有权重都乘以 $\sqrt{d_{model}}$。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Embeddings</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, d_model, vocab)</span>:</span></span><br><span class="line"> super(Embeddings, self).__init__()</span><br><span class="line"> self.lut = nn.Embedding(vocab, d_model)</span><br><span class="line"> self.d_model = d_model</span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line"> <span class="keyword">return</span> self.lut(x) * math.sqrt(self.d_model)</span><br></pre></td></tr></table></figure>
<h4 id="位置编码"><a href="#位置编码" class="headerlink" title="位置编码"></a>位置编码</h4><p>位置编码是 Transformer 模型中最后一个需要注意的结构，它对使用注意力机制实现序列任务也是非常重要的部分。如上文所述，Transformer 使用自注意力机制抽取序列的内部特征，但这种代替 RNN 或 CNN 抽取特征的方法有很大的局限性，即它不能捕捉序列的顺序。这样的模型即使能根据语境翻译出每一个词的意义，那也组不成完整的语句。</p>
<p>为了令模型能利用序列的顺序信息，我们必须植入一些关于词汇在序列中相对或绝对位置的信息。直观来说，如果语句中每一个词都有特定的位置，那么每一个词都可以使用向量编码位置信息。将这样的位置向量与词嵌入向量相结合，那么我们就为每一个词引入了一定的位置信息，注意力机制也就能分辨出不同位置的词。</p>
<p>谷歌研究者将「位置编码」添加到输入词嵌入中，位置编码有和词嵌入相同的维度 d_model，每一个词的位置编码与词嵌入向量相加可得出这个词的最终编码。目前有很多种位置编码，包括通过学习和固定表达式构建的。</p>
<p>在这一项实验中，谷歌研究者使用不同频率的正弦和预先函数：</p>
<p>$ P E _ { ( p o s , 2 i ) } = \sin \left( \operatorname { pos } / 10000 ^ { 2 i / d _ { \mathrm { model } } } \right) $</p>
<p>$ P E _ { ( p o s , 2 i + 1 ) } = \cos ( p o s / 10000 ^ { 2 i / d _ { \operatorname { mosel } } ) } $</p>
<p>其中 pos 为词的位置，i 为位置编码向量的第 i 个元素。给定词的位置 pos，我们可以将词映射到 d_model 维的位置向量，该向量第 i 个元素就由上面两个式子计算得出。也就是说，位置编码的每一个维度对应于正弦曲线，波长构成了从 2π 到 10000⋅2π 的等比数列。</p>
<p>上面构建了绝对位置的位置向量，但词的相对位置同样非常重要，这也就是谷歌研究者采用三角函数表征位置的精妙之处。正弦与余弦函数允许模型学习相对位置，这主要根据两个变换：sin(α+β)=sinα cosβ+cosα sinβ 以及 cos(α+β)=cosα cosβ−sinα sinβ。</p>
<p>对于词汇间固定的偏移量 k，位置向量 PE(pos+k) 可以通过 PE(pos) 与 PE(k) 的组合表示，这也就表示了语言间的相对位置。</p>
<p>以下定义了位置编码，其中我们对词嵌入与位置编码向量的和使用 Dropout，默认可令_drop=0.1。div_term 实现的是分母，而 pe[:, 0::2] 表示第二个维度从 0 开始以间隔为 2 取值，即偶数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PositionalEncoding</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line"> <span class="string">"Implement the PE function."</span></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, d_model, dropout, max_len=<span class="number">5000</span>)</span>:</span></span><br><span class="line"> super(PositionalEncoding, self).__init__()</span><br><span class="line"> self.dropout = nn.Dropout(p=dropout)</span><br><span class="line"></span><br><span class="line"> <span class="comment"># Compute the positional encodings once in log space.</span></span><br><span class="line"> pe = torch.zeros(max_len, d_model)</span><br><span class="line"> position = torch.arange(<span class="number">0</span>, max_len).unsqueeze(<span class="number">1</span>)</span><br><span class="line"> div_term = torch.exp(torch.arange(<span class="number">0</span>, d_model, <span class="number">2</span>) *</span><br><span class="line"> -(math.log(<span class="number">10000.0</span>) / d_model))</span><br><span class="line"> pe[:, <span class="number">0</span>::<span class="number">2</span>] = torch.sin(position * div_term)</span><br><span class="line"> pe[:, <span class="number">1</span>::<span class="number">2</span>] = torch.cos(position * div_term)</span><br><span class="line"> pe = pe.unsqueeze(<span class="number">0</span>)</span><br><span class="line"> self.register_buffer(<span class="string">'pe'</span>, pe)</span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line"> x = x + Variable(self.pe[:, :x.size(<span class="number">1</span>)], </span><br><span class="line"> requires_grad=<span class="keyword">False</span>)</span><br><span class="line"> <span class="keyword">return</span> self.dropout(x)</span><br></pre></td></tr></table></figure>
<p>以下将基于一个位置将不同的正弦曲线添加到位置编码向量中，曲线的频率和偏移量在每个维度上都不同。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">plt.figure(figsize=(15, 5))</span><br><span class="line">pe = PositionalEncoding(20, 0)</span><br><span class="line">y = pe.forward(Variable(torch.zeros(1, 100, 20)))</span><br><span class="line">plt.plot(np.arange(100), y[0, :, 4:8].data.numpy())</span><br><span class="line">plt.legend([&quot;dim %d&quot;%p for p in [4,5,6,7]])</span><br><span class="line">None</span><br></pre></td></tr></table></figure>
<div align="center"><img src="http://p598yuf6e.bkt.clouddn.com//transformer/image4.png" style="zoom:50%"></div>

<p>谷歌等研究者在原论文中表示他们同样对基于学习的位置编码进行了实验，并发现这两种方法会产生几乎相等的结果。所以按照性价比，他们还是选择了正弦曲线，因为它允许模型在训练中推断更长的序列。</p>
<h4 id="模型整体"><a href="#模型整体" class="headerlink" title="模型整体"></a>模型整体</h4><p>下面，我们定义了一个函数以构建模型的整个过程，其中 make_model 在输入原语词汇表和目标语词汇表后会构建两个词嵌入矩阵，而其它参数则会构建整个模型的架构。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">make_model</span><span class="params">(src_vocab, tgt_vocab, N=<span class="number">6</span>, </span></span></span><br><span class="line"><span class="function"><span class="params"> d_model=<span class="number">512</span>, d_ff=<span class="number">2048</span>, h=<span class="number">8</span>, dropout=<span class="number">0.1</span>)</span>:</span></span><br><span class="line"> <span class="string">"Helper: Construct a model from hyperparameters."</span></span><br><span class="line"> c = copy.deepcopy</span><br><span class="line"> attn = MultiHeadedAttention(h, d_model)</span><br><span class="line"> ff = PositionwiseFeedForward(d_model, d_ff, dropout)</span><br><span class="line"> position = PositionalEncoding(d_model, dropout)</span><br><span class="line"> model = EncoderDecoder(</span><br><span class="line"> Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),</span><br><span class="line"> Decoder(DecoderLayer(d_model, c(attn), c(attn), </span><br><span class="line"> c(ff), dropout), N),</span><br><span class="line"> nn.Sequential(Embeddings(d_model, src_vocab), c(position)),</span><br><span class="line"> nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),</span><br><span class="line"> Generator(d_model, tgt_vocab))</span><br><span class="line"></span><br><span class="line"> <span class="comment"># This was important from their code. </span></span><br><span class="line"> <span class="comment"># Initialize parameters with Glorot / fan_avg.</span></span><br><span class="line"> <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters():</span><br><span class="line"> <span class="keyword">if</span> p.dim() &gt; <span class="number">1</span>:</span><br><span class="line"> nn.init.xavier_uniform(p)</span><br><span class="line"> <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<p>在以上的代码中，make_model 函数将调用上面我们定义的各个模块，并将它们组合在一起。我们会将 Multi-Head Attention 子层、全连接子层和位置编码等结构传入编码器与解码器主体函数，再根据词嵌入向量与位置编码向量完成输入与标注输出的构建。以下简单地示例了如何使用 make_model 函数构建模型：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Small example model.</span></span><br><span class="line">tmp_model = make_model(<span class="number">10</span>, <span class="number">10</span>, <span class="number">2</span>)</span><br><span class="line"><span class="keyword">None</span></span><br></pre></td></tr></table></figure>
<h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><p>这一部分将描述模型的训练方案。首先需要介绍一些训练标准编码器解码器模型的工具，例如定义一个批量的目标以储存原语序列与目标语序列，并进行训练。前文的模型架构与函数定义我们主要参考的原论文，而后面的具体训练过程则主要参考了 Alexander 的实现经验。</p>
<h4 id="批量和掩码"><a href="#批量和掩码" class="headerlink" title="批量和掩码"></a>批量和掩码</h4><p>以下定义了保留一个批量数据的类，并且它会使用 Mask 在训练过程中限制目标语的访问序列。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Batch</span>:</span></span><br><span class="line"> <span class="string">"Object for holding a batch of data with mask during training."</span></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, src, trg=None, pad=<span class="number">0</span>)</span>:</span></span><br><span class="line"> self.src = src</span><br><span class="line"> self.src_mask = (src != pad).unsqueeze(<span class="number">-2</span>)</span><br><span class="line"> <span class="keyword">if</span> trg <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line"> self.trg = trg[:, :<span class="number">-1</span>]</span><br><span class="line"> self.trg_y = trg[:, <span class="number">1</span>:]</span><br><span class="line"> self.trg_mask = \</span><br><span class="line"> self.make_std_mask(self.trg, pad)</span><br><span class="line"> self.ntokens = (self.trg_y != pad).data.sum()</span><br><span class="line"></span><br><span class="line"><span class="meta"> @staticmethod</span></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">make_std_mask</span><span class="params">(tgt, pad)</span>:</span></span><br><span class="line"> <span class="string">"Create a mask to hide padding and future words."</span></span><br><span class="line"> tgt_mask = (tgt != pad).unsqueeze(<span class="number">-2</span>)</span><br><span class="line"> tgt_mask = tgt_mask &amp; Variable(</span><br><span class="line"> subsequent_mask(tgt.size(<span class="number">-1</span>)).type_as(tgt_mask.data))</span><br><span class="line"> <span class="keyword">return</span> tgt_mask</span><br></pre></td></tr></table></figure>
<p>我们下一步需要创建一般的训练和评分函数，以持续追踪损失的变化。在构建一般的损失函数后，我们就能根据它更新参数。</p>
<p>如下定义了训练中的迭代循环，我们使用 loss_compute() 函数计算损失函数，并且每运行 50 次迭代就输出一次训练损失，这有利于监控训练情况。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_epoch</span><span class="params">(data_iter, model, loss_compute)</span>:</span></span><br><span class="line"> <span class="string">"Standard Training and Logging Function"</span></span><br><span class="line"> start = time.time()</span><br><span class="line"> total_tokens = <span class="number">0</span></span><br><span class="line"> total_loss = <span class="number">0</span></span><br><span class="line"> tokens = <span class="number">0</span></span><br><span class="line"> <span class="keyword">for</span> i, batch <span class="keyword">in</span> enumerate(data_iter):</span><br><span class="line"> out = model.forward(batch.src, batch.trg, </span><br><span class="line"> batch.src_mask, batch.trg_mask)</span><br><span class="line"> loss = loss_compute(out, batch.trg_y, batch.ntokens)</span><br><span class="line"> total_loss += loss</span><br><span class="line"> total_tokens += batch.ntokens</span><br><span class="line"> tokens += batch.ntokens</span><br><span class="line"> <span class="keyword">if</span> i % <span class="number">50</span> == <span class="number">1</span>:</span><br><span class="line"> elapsed = time.time() - start</span><br><span class="line"> print(<span class="string">"Epoch Step: %d Loss: %f Tokens per Sec: %f"</span> %</span><br><span class="line"> (i, loss / batch.ntokens, tokens / elapsed))</span><br><span class="line"> start = time.time()</span><br><span class="line"> tokens = <span class="number">0</span></span><br><span class="line"> <span class="keyword">return</span> total_loss / total_tokens</span><br></pre></td></tr></table></figure>
<h4 id="训练数据与分批"><a href="#训练数据与分批" class="headerlink" title="训练数据与分批"></a>训练数据与分批</h4><p>Alexander 等人的模型在标准的 WMT 2014 英语-德语数据集上进行训练，这个数据集包含 450 万条语句对。语句已经使用双字节编码（byte-pair encoding）处理，且拥有约为 37000 个符号的原语-目标语共享词汇库。对于英语-法语的翻译任务，. 原论文作者使用了更大的 WMT 2014 英语-法语数据集，它包含 3600 万条语句，且将符号分割为包含 32000 个 word-piece 的词汇库。</p>
<p>原论文表示所有语句对将一同执行分批操作，并逼近序列长度。每一个训练批量包含一组语句对，大约分别有 25000 个原语词汇和目标语词汇。</p>
<p>Alexander 等人使用 torch text 进行分批，具体的细节将在后面讨论。下面的函数使用 torchtext 函数创建批量数据，并确保批量大小会填充到最大且不会超过阈值（使用 8 块 GPU，阈值为 25000）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">global</span> max_src_in_batch, max_tgt_in_batch</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">batch_size_fn</span><span class="params">(new, count, sofar)</span>:</span></span><br><span class="line"> <span class="string">"Keep augmenting batch and calculate total number of tokens + padding."</span></span><br><span class="line"> <span class="keyword">global</span> max_src_in_batch, max_tgt_in_batch</span><br><span class="line"> <span class="keyword">if</span> count == <span class="number">1</span>:</span><br><span class="line"> max_src_in_batch = <span class="number">0</span></span><br><span class="line"> max_tgt_in_batch = <span class="number">0</span></span><br><span class="line"> max_src_in_batch = max(max_src_in_batch, len(new.src))</span><br><span class="line"> max_tgt_in_batch = max(max_tgt_in_batch, len(new.trg) + <span class="number">2</span>)</span><br><span class="line"> src_elements = count * max_src_in_batch</span><br><span class="line"> tgt_elements = count * max_tgt_in_batch</span><br><span class="line"> <span class="keyword">return</span> max(src_elements, tgt_elements)</span><br></pre></td></tr></table></figure>
<p>batch_size_fn 将抽取批量数据，且每一个批量都抽取最大原语序列长度和最大目标语序列长度，如果长度不够就使用零填充增加。</p>
<h4 id="硬件与策略"><a href="#硬件与策略" class="headerlink" title="硬件与策略"></a>硬件与策略</h4><p>原论文在一台机器上使用 8 块 NVIDIA P100 GPU 训练模型，基本模型使用了论文中描述的超参数，每一次迭代大概需要 0.4 秒。基本模型最后迭代了 100000 次，共花了 12 个小时。而对于大模型，每一次迭代需要花 1 秒钟，所以训练 300000 个迭代大概需要三天半。但我们后面的真实案例并不需要使用如此大的计算力，因为我们的数据集相对要小一些。</p>
<h4 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h4><p>原论文使用了 Adam 优化器，其中$β_1=0.9$、 $β_2=0.98$ 和 $ϵ=10^{−9}$。在训练中，研究者会改变学习率为 l_rate=d−0.5model⋅min(step_num−0.5,step_num⋅warmup_steps−1.5)。</p>
<p>学习率的这种变化对应于在预热训练中线性地增加学习率，然后再与迭代数的平方根成比例地减小。这种 1cycle 学习策略在实践中有非常好的效果，一般使用这种策略的模型要比传统的方法收敛更快。在这个实验中，模型采用的预热迭代数为 4000。注意，这一部分非常重要，我们需要以以下配置训练模型。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NoamOpt</span>:</span></span><br><span class="line"> <span class="string">"Optim wrapper that implements rate."</span></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, model_size, factor, warmup, optimizer)</span>:</span></span><br><span class="line"> self.optimizer = optimizer</span><br><span class="line"> self._step = <span class="number">0</span></span><br><span class="line"> self.warmup = warmup</span><br><span class="line"> self.factor = factor</span><br><span class="line"> self.model_size = model_size</span><br><span class="line"> self._rate = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">step</span><span class="params">(self)</span>:</span></span><br><span class="line"> <span class="string">"Update parameters and rate"</span></span><br><span class="line"> self._step += <span class="number">1</span></span><br><span class="line"> rate = self.rate()</span><br><span class="line"> <span class="keyword">for</span> p <span class="keyword">in</span> self.optimizer.param_groups:</span><br><span class="line"> p[<span class="string">'lr'</span>] = rate</span><br><span class="line"> self._rate = rate</span><br><span class="line"> self.optimizer.step()</span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">rate</span><span class="params">(self, step = None)</span>:</span></span><br><span class="line"> <span class="string">"Implement `lrate` above"</span></span><br><span class="line"> <span class="keyword">if</span> step <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line"> step = self._step</span><br><span class="line"> <span class="keyword">return</span> self.factor * \</span><br><span class="line"> (self.model_size ** (<span class="number">-0.5</span>) *</span><br><span class="line"> min(step ** (<span class="number">-0.5</span>), step * self.warmup ** (<span class="number">-1.5</span>)))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_std_opt</span><span class="params">(model)</span>:</span></span><br><span class="line"> <span class="keyword">return</span> NoamOpt(model.src_embed[<span class="number">0</span>].d_model, <span class="number">2</span>, <span class="number">4000</span>,</span><br><span class="line"> torch.optim.Adam(model.parameters(), lr=<span class="number">0</span>, betas=(<span class="number">0.9</span>, <span class="number">0.98</span>), eps=<span class="number">1e-9</span>))</span><br></pre></td></tr></table></figure>
<p>使用不同模型大小和最优化超参数下的变化曲线：</p>
<div align="center"><img src="http://p598yuf6e.bkt.clouddn.com//transformer/image5.png" style="zoom:40%"></div>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Three settings of the lrate hyperparameters.</span></span><br><span class="line">opts = [NoamOpt(<span class="number">512</span>, <span class="number">1</span>, <span class="number">4000</span>, <span class="keyword">None</span>), </span><br><span class="line"> NoamOpt(<span class="number">512</span>, <span class="number">1</span>, <span class="number">8000</span>, <span class="keyword">None</span>),</span><br><span class="line"> NoamOpt(<span class="number">256</span>, <span class="number">1</span>, <span class="number">4000</span>, <span class="keyword">None</span>)]</span><br><span class="line">plt.plot(np.arange(<span class="number">1</span>, <span class="number">20000</span>), [[opt.rate(i) <span class="keyword">for</span> opt <span class="keyword">in</span> opts] <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">20000</span>)])</span><br><span class="line">plt.legend([<span class="string">"512:4000"</span>, <span class="string">"512:8000"</span>, <span class="string">"256:4000"</span>])</span><br><span class="line"><span class="keyword">None</span></span><br></pre></td></tr></table></figure>
<h4 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h4><p><strong>标签平滑</strong></p>
<p>在训练中，Alexander 等人使用了标签平滑的方法，且平滑值ϵ_ls=0.1。这可能会有损困惑度，因为模型将变得更加不确定它所做的预测，不过这样还是提升了准确度和 BLEU 分数。</p>
<p>Harvard NLP 最终使用 KL 散度实现了标签平滑，与其使用 one-hot 目标分布，他们选择了创建一个对正确词有置信度的分布，而其它平滑的概率质量分布将贯穿整个词汇库。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LabelSmoothing</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line"> <span class="string">"Implement label smoothing."</span></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, size, padding_idx, smoothing=<span class="number">0.0</span>)</span>:</span></span><br><span class="line"> super(LabelSmoothing, self).__init__()</span><br><span class="line"> self.criterion = nn.KLDivLoss(size_average=<span class="keyword">False</span>)</span><br><span class="line"> self.padding_idx = padding_idx</span><br><span class="line"> self.confidence = <span class="number">1.0</span> - smoothing</span><br><span class="line"> self.smoothing = smoothing</span><br><span class="line"> self.size = size</span><br><span class="line"> self.true_dist = <span class="keyword">None</span></span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, target)</span>:</span></span><br><span class="line"> <span class="keyword">assert</span> x.size(<span class="number">1</span>) == self.size</span><br><span class="line"> true_dist = x.data.clone()</span><br><span class="line"> true_dist.fill_(self.smoothing / (self.size - <span class="number">2</span>))</span><br><span class="line"> true_dist.scatter_(<span class="number">1</span>, target.data.unsqueeze(<span class="number">1</span>), self.confidence)</span><br><span class="line"> true_dist[:, self.padding_idx] = <span class="number">0</span></span><br><span class="line"> mask = torch.nonzero(target.data == self.padding_idx)</span><br><span class="line"> <span class="keyword">if</span> mask.dim() &gt; <span class="number">0</span>:</span><br><span class="line"> true_dist.index_fill_(<span class="number">0</span>, mask.squeeze(), <span class="number">0.0</span>)</span><br><span class="line"> self.true_dist = true_dist</span><br><span class="line"> <span class="keyword">return</span> self.criterion(x, Variable(true_dist, requires_grad=<span class="keyword">False</span>))</span><br></pre></td></tr></table></figure>
<p>下面，我们可以了解到概率质量如何基于置信度分配到词。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Example of label smoothing.</span></span><br><span class="line">crit = LabelSmoothing(<span class="number">5</span>, <span class="number">0</span>, <span class="number">0.4</span>)</span><br><span class="line">predict = torch.FloatTensor([[<span class="number">0</span>, <span class="number">0.2</span>, <span class="number">0.7</span>, <span class="number">0.1</span>, <span class="number">0</span>],</span><br><span class="line"> [<span class="number">0</span>, <span class="number">0.2</span>, <span class="number">0.7</span>, <span class="number">0.1</span>, <span class="number">0</span>], </span><br><span class="line"> [<span class="number">0</span>, <span class="number">0.2</span>, <span class="number">0.7</span>, <span class="number">0.1</span>, <span class="number">0</span>]])</span><br><span class="line">v = crit(Variable(predict.log()), </span><br><span class="line"> Variable(torch.LongTensor([<span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>])))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Show the target distributions expected by the system.</span></span><br><span class="line">plt.imshow(crit.true_dist)</span><br><span class="line"><span class="keyword">None</span></span><br></pre></td></tr></table></figure>
<div align="center"><img src="http://p598yuf6e.bkt.clouddn.com//transformer/image6.png" style="zoom:40%"></div>

<p>标签平滑实际上在模型对某些选项非常有信心的时候会惩罚它。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">crit = LabelSmoothing(<span class="number">5</span>, <span class="number">0</span>, <span class="number">0.1</span>)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss</span><span class="params">(x)</span>:</span></span><br><span class="line"> d = x + <span class="number">3</span> * <span class="number">1</span></span><br><span class="line"> predict = torch.FloatTensor([[<span class="number">0</span>, x / d, <span class="number">1</span> / d, <span class="number">1</span> / d, <span class="number">1</span> / d],</span><br><span class="line"> ])</span><br><span class="line"> <span class="comment">#print(predict)</span></span><br><span class="line"> <span class="keyword">return</span> crit(Variable(predict.log()),</span><br><span class="line"> Variable(torch.LongTensor([<span class="number">1</span>]))).data[<span class="number">0</span>]</span><br><span class="line">plt.plot(np.arange(<span class="number">1</span>, <span class="number">100</span>), [loss(x) <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">100</span>)])</span><br><span class="line"><span class="keyword">None</span></span><br></pre></td></tr></table></figure>
<div align="center"><img src="http://p598yuf6e.bkt.clouddn.com//transformer/image7.png" style="zoom:40%"></div>

<h3 id="简单的序列翻译案例"><a href="#简单的序列翻译案例" class="headerlink" title="简单的序列翻译案例"></a>简单的序列翻译案例</h3><p>我们可以从简单的复制任务开始尝试。若从小词汇库给定输入符号的一个随机集合，我们的目标是反向生成这些相同的符号。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_gen</span><span class="params">(V, batch, nbatches)</span>:</span></span><br><span class="line"> <span class="string">"Generate random data for a src-tgt copy task."</span></span><br><span class="line"> <span class="keyword">for</span> i <span class="keyword">in</span> range(nbatches):</span><br><span class="line"> data = torch.from_numpy(np.random.randint(<span class="number">1</span>, V, size=(batch, <span class="number">10</span>)))</span><br><span class="line"> data[:, <span class="number">0</span>] = <span class="number">1</span></span><br><span class="line"> src = Variable(data, requires_grad=<span class="keyword">False</span>)</span><br><span class="line"> tgt = Variable(data, requires_grad=<span class="keyword">False</span>)</span><br><span class="line"> <span class="keyword">yield</span> Batch(src, tgt, <span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<h4 id="计算模型损失"><a href="#计算模型损失" class="headerlink" title="计算模型损失"></a>计算模型损失</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SimpleLossCompute</span>:</span></span><br><span class="line"> <span class="string">"A simple loss compute and train function."</span></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, generator, criterion, opt=None)</span>:</span></span><br><span class="line"> self.generator = generator</span><br><span class="line"> self.criterion = criterion</span><br><span class="line"> self.opt = opt</span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(self, x, y, norm)</span>:</span></span><br><span class="line"> x = self.generator(x)</span><br><span class="line"> loss = self.criterion(x.contiguous().view(<span class="number">-1</span>, x.size(<span class="number">-1</span>)), </span><br><span class="line"> y.contiguous().view(<span class="number">-1</span>)) / norm</span><br><span class="line"> loss.backward()</span><br><span class="line"> <span class="keyword">if</span> self.opt <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line"> self.opt.step()</span><br><span class="line"> self.opt.optimizer.zero_grad()</span><br><span class="line"> <span class="keyword">return</span> loss.data[<span class="number">0</span>] * norm</span><br></pre></td></tr></table></figure>
<h4 id="贪婪解码"><a href="#贪婪解码" class="headerlink" title="贪婪解码"></a>贪婪解码</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Train the simple copy task.</span></span><br><span class="line">V = <span class="number">11</span></span><br><span class="line">criterion = LabelSmoothing(size=V, padding_idx=<span class="number">0</span>, smoothing=<span class="number">0.0</span>)</span><br><span class="line">model = make_model(V, V, N=<span class="number">2</span>)</span><br><span class="line">model_opt = NoamOpt(model.src_embed[<span class="number">0</span>].d_model, <span class="number">1</span>, <span class="number">400</span>,</span><br><span class="line"> torch.optim.Adam(model.parameters(), lr=<span class="number">0</span>, betas=(<span class="number">0.9</span>, <span class="number">0.98</span>), eps=<span class="number">1e-9</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line"> model.train()</span><br><span class="line"> run_epoch(data_gen(V, <span class="number">30</span>, <span class="number">20</span>), model, </span><br><span class="line"> SimpleLossCompute(model.generator, criterion, model_opt))</span><br><span class="line"> model.eval()</span><br><span class="line"> print(run_epoch(data_gen(V, <span class="number">30</span>, <span class="number">5</span>), model, </span><br><span class="line"> SimpleLossCompute(model.generator, criterion, <span class="keyword">None</span>)))</span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">3.023465</span> Tokens per Sec: <span class="number">403.074173</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">1.920030</span> Tokens per Sec: <span class="number">641.689380</span></span><br><span class="line"><span class="number">1.9274832487106324</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">1.940011</span> Tokens per Sec: <span class="number">432.003378</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">1.699767</span> Tokens per Sec: <span class="number">641.979665</span></span><br><span class="line"><span class="number">1.657595729827881</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">1.860276</span> Tokens per Sec: <span class="number">433.320240</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">1.546011</span> Tokens per Sec: <span class="number">640.537198</span></span><br><span class="line"><span class="number">1.4888023376464843</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">1.278768</span> Tokens per Sec: <span class="number">433.568756</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">1.062384</span> Tokens per Sec: <span class="number">642.542067</span></span><br><span class="line"><span class="number">0.9853351473808288</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">1.269471</span> Tokens per Sec: <span class="number">433.388727</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">0.590709</span> Tokens per Sec: <span class="number">642.862135</span></span><br><span class="line"><span class="number">0.34273059368133546</span></span><br></pre></td></tr></table></figure>
<p>这些代码将简单地使用贪婪解码预测译文。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">greedy_decode</span><span class="params">(model, src, src_mask, max_len, start_symbol)</span>:</span></span><br><span class="line"> memory = model.encode(src, src_mask)</span><br><span class="line"> ys = torch.ones(<span class="number">1</span>, <span class="number">1</span>).fill_(start_symbol).type_as(src.data)</span><br><span class="line"> <span class="keyword">for</span> i <span class="keyword">in</span> range(max_len<span class="number">-1</span>):</span><br><span class="line"> out = model.decode(memory, src_mask, </span><br><span class="line"> Variable(ys), </span><br><span class="line"> Variable(subsequent_mask(ys.size(<span class="number">1</span>))</span><br><span class="line"> .type_as(src.data)))</span><br><span class="line"> prob = model.generator(out[:, <span class="number">-1</span>])</span><br><span class="line"> _, next_word = torch.max(prob, dim = <span class="number">1</span>)</span><br><span class="line"> next_word = next_word.data[<span class="number">0</span>]</span><br><span class="line"> ys = torch.cat([ys, </span><br><span class="line"> torch.ones(<span class="number">1</span>, <span class="number">1</span>).type_as(src.data).fill_(next_word)], dim=<span class="number">1</span>)</span><br><span class="line"> <span class="keyword">return</span> ys</span><br><span class="line"></span><br><span class="line">model.eval()</span><br><span class="line">src = Variable(torch.LongTensor([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">10</span>]]) )</span><br><span class="line">src_mask = Variable(torch.ones(<span class="number">1</span>, <span class="number">1</span>, <span class="number">10</span>) )</span><br><span class="line">print(greedy_decode(model, src, src_mask, max_len=<span class="number">10</span>, start_symbol=<span class="number">1</span>))</span><br><span class="line"> <span class="number">1</span> <span class="number">2</span> <span class="number">3</span> <span class="number">4</span> <span class="number">5</span> <span class="number">6</span> <span class="number">7</span> <span class="number">8</span> <span class="number">9</span> <span class="number">10</span></span><br><span class="line">[torch.LongTensor of size <span class="number">1</span>x10]</span><br></pre></td></tr></table></figure>
<h3 id="真实案例"><a href="#真实案例" class="headerlink" title="真实案例"></a>真实案例</h3><p>现在，我们将使用 IWSLT 德语-英语数据集实现翻译任务。该任务要比论文中讨论的 WMT 任务稍微小一点，但足够展示整个系统。我们同样还展示了如何使用多 GPU 处理来令加速训练过程。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!pip install torchtext spacy</span></span><br><span class="line"><span class="comment">#!python -m spacy download en</span></span><br><span class="line"><span class="comment">#!python -m spacy download de</span></span><br></pre></td></tr></table></figure>
<h4 id="数据加载"><a href="#数据加载" class="headerlink" title="数据加载"></a>数据加载</h4><p>我们将使用 torchtext 和 spacy 加载数据集，并实现分词。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># For data loading.</span></span><br><span class="line"><span class="keyword">from</span> torchtext <span class="keyword">import</span> data, datasets</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">True</span>:</span><br><span class="line"> <span class="keyword">import</span> spacy</span><br><span class="line"> spacy_de = spacy.load(<span class="string">'de'</span>)</span><br><span class="line"> spacy_en = spacy.load(<span class="string">'en'</span>)</span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">tokenize_de</span><span class="params">(text)</span>:</span></span><br><span class="line"> <span class="keyword">return</span> [tok.text <span class="keyword">for</span> tok <span class="keyword">in</span> spacy_de.tokenizer(text)]</span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">tokenize_en</span><span class="params">(text)</span>:</span></span><br><span class="line"> <span class="keyword">return</span> [tok.text <span class="keyword">for</span> tok <span class="keyword">in</span> spacy_en.tokenizer(text)]</span><br><span class="line"></span><br><span class="line"> BOS_WORD = <span class="string">'&lt;s&gt;'</span></span><br><span class="line"> EOS_WORD = <span class="string">'&lt;/s&gt;'</span></span><br><span class="line"> BLANK_WORD = <span class="string">"&lt;blank&gt;"</span></span><br><span class="line"> SRC = data.Field(tokenize=tokenize_de, pad_token=BLANK_WORD)</span><br><span class="line"> TGT = data.Field(tokenize=tokenize_en, init_token = BOS_WORD, </span><br><span class="line"> eos_token = EOS_WORD, pad_token=BLANK_WORD)</span><br><span class="line"></span><br><span class="line"> MAX_LEN = <span class="number">100</span></span><br><span class="line"> train, val, test = datasets.IWSLT.splits(</span><br><span class="line"> exts=(<span class="string">'.de'</span>, <span class="string">'.en'</span>), fields=(SRC, TGT), </span><br><span class="line"> filter_pred=<span class="keyword">lambda</span> x: len(vars(x)[<span class="string">'src'</span>]) &lt;= MAX_LEN <span class="keyword">and</span> </span><br><span class="line"> len(vars(x)[<span class="string">'trg'</span>]) &lt;= MAX_LEN)</span><br><span class="line"> MIN_FREQ = <span class="number">2</span></span><br><span class="line"> SRC.build_vocab(train.src, min_freq=MIN_FREQ)</span><br><span class="line"> TGT.build_vocab(train.trg, min_freq=MIN_FREQ)</span><br></pre></td></tr></table></figure>
<p>我们希望有非常均匀的批量，且有最小的填充，因此我们必须对默认的 torchtext 分批函数进行修改。这段代码修改了默认的分批过程，以确保我们能搜索足够的语句以找到紧凑的批量。</p>
<h4 id="数据迭代器"><a href="#数据迭代器" class="headerlink" title="数据迭代器"></a>数据迭代器</h4><p>迭代器定义了分批过程的多项操作，包括数据清洗、整理和分批等。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyIterator</span><span class="params">(data.Iterator)</span>:</span></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">create_batches</span><span class="params">(self)</span>:</span></span><br><span class="line"> <span class="keyword">if</span> self.train:</span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">pool</span><span class="params">(d, random_shuffler)</span>:</span></span><br><span class="line"> <span class="keyword">for</span> p <span class="keyword">in</span> data.batch(d, self.batch_size * <span class="number">100</span>):</span><br><span class="line"> p_batch = data.batch(</span><br><span class="line"> sorted(p, key=self.sort_key),</span><br><span class="line"> self.batch_size, self.batch_size_fn)</span><br><span class="line"> <span class="keyword">for</span> b <span class="keyword">in</span> random_shuffler(list(p_batch)):</span><br><span class="line"> <span class="keyword">yield</span> b</span><br><span class="line"> self.batches = pool(self.data(), self.random_shuffler)</span><br><span class="line"></span><br><span class="line"> <span class="keyword">else</span>:</span><br><span class="line"> self.batches = []</span><br><span class="line"> <span class="keyword">for</span> b <span class="keyword">in</span> data.batch(self.data(), self.batch_size,</span><br><span class="line"> self.batch_size_fn):</span><br><span class="line"> self.batches.append(sorted(b, key=self.sort_key))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rebatch</span><span class="params">(pad_idx, batch)</span>:</span></span><br><span class="line"> <span class="string">"Fix order in torchtext to match ours"</span></span><br><span class="line"> src, trg = batch.src.transpose(<span class="number">0</span>, <span class="number">1</span>), batch.trg.transpose(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line"> <span class="keyword">return</span> Batch(src, trg, pad_idx)</span><br></pre></td></tr></table></figure>
<h4 id="多-GPU-训练"><a href="#多-GPU-训练" class="headerlink" title="多 GPU 训练"></a>多 GPU 训练</h4><p>最后为了快速训练，我们使用了多块 GPU。这段代码将实现多 GPU 的词生成，但它并不是针对 Transformer 的具体方法，所以这里并不会具体讨论。多 GPU 训练的基本思想即在训练过程中将词生成分割为语块（chunks），并传入不同的 GPU 实现并行处理，我们可以使用 PyTorch 并行基元实现这一点。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">replicate - split modules onto different gpus.</span><br><span class="line">scatter - split batches onto different gpus</span><br><span class="line">parallel_apply - apply module to batches on different gpus</span><br><span class="line">gather - pull scattered data back onto one gpu.</span><br><span class="line">nn.DataParallel - a special module wrapper that calls these all before evaluating.</span><br><span class="line"><span class="comment"># Skip if not interested in multigpu.</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MultiGPULossCompute</span>:</span></span><br><span class="line"> <span class="string">"A multi-gpu loss compute and train function."</span></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, generator, criterion, devices, opt=None, chunk_size=<span class="number">5</span>)</span>:</span></span><br><span class="line"> <span class="comment"># Send out to different gpus.</span></span><br><span class="line"> self.generator = generator</span><br><span class="line"> self.criterion = nn.parallel.replicate(criterion, </span><br><span class="line"> devices=devices)</span><br><span class="line"> self.opt = opt</span><br><span class="line"> self.devices = devices</span><br><span class="line"> self.chunk_size = chunk_size</span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(self, out, targets, normalize)</span>:</span></span><br><span class="line"> total = <span class="number">0.0</span></span><br><span class="line"> generator = nn.parallel.replicate(self.generator, </span><br><span class="line"> devices=self.devices)</span><br><span class="line"> out_scatter = nn.parallel.scatter(out, </span><br><span class="line"> target_gpus=self.devices)</span><br><span class="line"> out_grad = [[] <span class="keyword">for</span> _ <span class="keyword">in</span> out_scatter]</span><br><span class="line"> targets = nn.parallel.scatter(targets, </span><br><span class="line"> target_gpus=self.devices)</span><br><span class="line"></span><br><span class="line"> <span class="comment"># Divide generating into chunks.</span></span><br><span class="line"> chunk_size = self.chunk_size</span><br><span class="line"> <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, out_scatter[<span class="number">0</span>].size(<span class="number">1</span>), chunk_size):</span><br><span class="line"> <span class="comment"># Predict distributions</span></span><br><span class="line"> out_column = [[Variable(o[:, i:i+chunk_size].data, </span><br><span class="line"> requires_grad=self.opt <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>)] </span><br><span class="line"> <span class="keyword">for</span> o <span class="keyword">in</span> out_scatter]</span><br><span class="line"> gen = nn.parallel.parallel_apply(generator, out_column)</span><br><span class="line"></span><br><span class="line"> <span class="comment"># Compute loss. </span></span><br><span class="line"> y = [(g.contiguous().view(<span class="number">-1</span>, g.size(<span class="number">-1</span>)), </span><br><span class="line"> t[:, i:i+chunk_size].contiguous().view(<span class="number">-1</span>)) </span><br><span class="line"> <span class="keyword">for</span> g, t <span class="keyword">in</span> zip(gen, targets)]</span><br><span class="line"> loss = nn.parallel.parallel_apply(self.criterion, y)</span><br><span class="line"></span><br><span class="line"> <span class="comment"># Sum and normalize loss</span></span><br><span class="line"> l = nn.parallel.gather(loss, </span><br><span class="line"> target_device=self.devices[<span class="number">0</span>])</span><br><span class="line"> l = l.sum()[<span class="number">0</span>] / normalize</span><br><span class="line"> total += l.data[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"> <span class="comment"># Backprop loss to output of transformer</span></span><br><span class="line"> <span class="keyword">if</span> self.opt <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line"> l.backward()</span><br><span class="line"> <span class="keyword">for</span> j, l <span class="keyword">in</span> enumerate(loss):</span><br><span class="line"> out_grad[j].append(out_column[j][<span class="number">0</span>].grad.data.clone())</span><br><span class="line"></span><br><span class="line"> <span class="comment"># Backprop all loss through transformer. </span></span><br><span class="line"> <span class="keyword">if</span> self.opt <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line"> out_grad = [Variable(torch.cat(og, dim=<span class="number">1</span>)) <span class="keyword">for</span> og <span class="keyword">in</span> out_grad]</span><br><span class="line"> o1 = out</span><br><span class="line"> o2 = nn.parallel.gather(out_grad, </span><br><span class="line"> target_device=self.devices[<span class="number">0</span>])</span><br><span class="line"> o1.backward(gradient=o2)</span><br><span class="line"> self.opt.step()</span><br><span class="line"> self.opt.optimizer.zero_grad()</span><br><span class="line"> <span class="keyword">return</span> total * normalize</span><br></pre></td></tr></table></figure>
<p>下面，我们利用前面定义的函数创建了模型、度量标准、优化器、数据迭代器和并行化：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># GPUs to use</span></span><br><span class="line">devices = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">True</span>:</span><br><span class="line"> pad_idx = TGT.vocab.stoi[<span class="string">"&lt;blank&gt;"</span>]</span><br><span class="line"> model = make_model(len(SRC.vocab), len(TGT.vocab), N=<span class="number">6</span>)</span><br><span class="line"> model.cuda()</span><br><span class="line"> criterion = LabelSmoothing(size=len(TGT.vocab), padding_idx=pad_idx, smoothing=<span class="number">0.1</span>)</span><br><span class="line"> criterion.cuda()</span><br><span class="line"> BATCH_SIZE = <span class="number">12000</span></span><br><span class="line"> train_iter = MyIterator(train, batch_size=BATCH_SIZE, device=<span class="number">0</span>,</span><br><span class="line"> repeat=<span class="keyword">False</span>, sort_key=<span class="keyword">lambda</span> x: (len(x.src), len(x.trg)),</span><br><span class="line"> batch_size_fn=batch_size_fn, train=<span class="keyword">True</span>)</span><br><span class="line"> valid_iter = MyIterator(val, batch_size=BATCH_SIZE, device=<span class="number">0</span>,</span><br><span class="line"> repeat=<span class="keyword">False</span>, sort_key=<span class="keyword">lambda</span> x: (len(x.src), len(x.trg)),</span><br><span class="line"> batch_size_fn=batch_size_fn, train=<span class="keyword">False</span>)</span><br><span class="line"> model_par = nn.DataParallel(model, device_ids=devices)</span><br><span class="line"><span class="keyword">None</span></span><br></pre></td></tr></table></figure>
<p>下面可以训练模型了，Harvard NLP 团队首先运行了一些预热迭代，但是其它的设定都能使用默认的参数。在带有 4 块 Tesla V100 的 AWS p3.8xlarge 中，批量大小为 12000 的情况下每秒能运行 27000 个词。</p>
<h4 id="训练系统"><a href="#训练系统" class="headerlink" title="训练系统"></a>训练系统</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!wget https://s3.amazonaws.com/opennmt-models/iwslt.pt</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">False</span>:</span><br><span class="line"> model_opt = NoamOpt(model.src_embed[<span class="number">0</span>].d_model, <span class="number">1</span>, <span class="number">2000</span>,</span><br><span class="line"> torch.optim.Adam(model.parameters(), lr=<span class="number">0</span>, betas=(<span class="number">0.9</span>, <span class="number">0.98</span>), eps=<span class="number">1e-9</span>))</span><br><span class="line"> <span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line"> model_par.train()</span><br><span class="line"> run_epoch((rebatch(pad_idx, b) <span class="keyword">for</span> b <span class="keyword">in</span> train_iter), </span><br><span class="line"> model_par, </span><br><span class="line"> MultiGPULossCompute(model.generator, criterion, </span><br><span class="line"> devices=devices, opt=model_opt))</span><br><span class="line"> model_par.eval()</span><br><span class="line"> loss = run_epoch((rebatch(pad_idx, b) <span class="keyword">for</span> b <span class="keyword">in</span> valid_iter), </span><br><span class="line"> model_par, </span><br><span class="line"> MultiGPULossCompute(model.generator, criterion, </span><br><span class="line"> devices=devices, opt=<span class="keyword">None</span>))</span><br><span class="line"> print(loss)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line"> model = torch.load(<span class="string">"iwslt.pt"</span>)</span><br></pre></td></tr></table></figure>
<p>一旦训练完成了，我们就能解码模型并生成一组翻译，下面我们简单地翻译了验证集中的第一句话。该数据集非常小，所以模型通过贪婪搜索也能获得不错的翻译效果。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i, batch <span class="keyword">in</span> enumerate(valid_iter):</span><br><span class="line"> src = batch.src.transpose(<span class="number">0</span>, <span class="number">1</span>)[:<span class="number">1</span>]</span><br><span class="line"> src_mask = (src != SRC.vocab.stoi[<span class="string">"&lt;blank&gt;"</span>]).unsqueeze(<span class="number">-2</span>)</span><br><span class="line"> out = greedy_decode(model, src, src_mask, </span><br><span class="line"> max_len=<span class="number">60</span>, start_symbol=TGT.vocab.stoi[<span class="string">"&lt;s&gt;"</span>])</span><br><span class="line"> print(<span class="string">"Translation:"</span>, end=<span class="string">"\t"</span>)</span><br><span class="line"> <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, out.size(<span class="number">1</span>)):</span><br><span class="line"> sym = TGT.vocab.itos[out[<span class="number">0</span>, i]]</span><br><span class="line"> <span class="keyword">if</span> sym == <span class="string">"&lt;/s&gt;"</span>: <span class="keyword">break</span></span><br><span class="line"> print(sym, end =<span class="string">" "</span>)</span><br><span class="line"> print()</span><br><span class="line"> print(<span class="string">"Target:"</span>, end=<span class="string">"\t"</span>)</span><br><span class="line"> <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, batch.trg.size(<span class="number">0</span>)):</span><br><span class="line"> sym = TGT.vocab.itos[batch.trg.data[i, <span class="number">0</span>]]</span><br><span class="line"> <span class="keyword">if</span> sym == <span class="string">"&lt;/s&gt;"</span>: <span class="keyword">break</span></span><br><span class="line"> print(sym, end =<span class="string">" "</span>)</span><br><span class="line"> print()</span><br><span class="line"> <span class="keyword">break</span></span><br><span class="line">Translation: &lt;unk&gt; &lt;unk&gt; . In my language , that means , thank you very much . </span><br><span class="line">Gold: &lt;unk&gt; &lt;unk&gt; . It means <span class="keyword">in</span> my language , thank you very much .</span><br></pre></td></tr></table></figure>
<h4 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h4><p>在 WMT 2014 英语到法语的翻译任务中，原论文中的大型的 Transformer 模型实现了 41.0 的 BLEU 分值，它要比以前所有的单模型效果更好，且只有前面顶级的模型 1/4 的训练成本。在 Harvard NLP 团队的实现中，OpenNMT-py 版本的模型在 EN-DE WMT 数据集上实现了 26.9 的 BLEU 分值。</p>


<!-- Tags -->



<div class="tags">
    <a href="/tags/序列建模/" class="button small">序列建模</a> <a href="/tags/神经机器翻译/" class="button small">神经机器翻译</a>
</div>



<!-- Comments -->
<div>
    


</div>



            </div>
        </div>

        <!-- Footer -->
<footer id="footer">
    <div class="inner">
        <section>
            <h2>About</h2>
            <div>
                If you are also interesting in Machine Learning, contact me with email：horatio.j.s.y@gmail.com.
            </div>
        </section>
        <section>
            <h2>Follow</h2>
            <ul class="icons">
                
                    <li><a href="https://twitter.com/Horatio_JSY" class="icon style2 fa-twitter" target="_blank" ><span class="label">Twitter</span></a></li>
                
                
                    <li><a href="https://www.facebook.com/horatio.jsy.3" class="icon style2 fa-facebook" target="_blank" ><span class="label">Facebook</span></a></li>
                
                
                
                
                    <li><a href="https://github.com/HoratioJSY" class="icon style2 fa-github" target="_blank" ><span class="label">GitHub</span></a></li>
                
                
                
                
                    <li><a href="https://500px.com/siyuan" class="icon style2 fa-500px" target="_blank" ><span class="label">500px</span></a></li>
                
                
                
            </ul>
        </section>
        <ul class="copyright">
            <li>&copy; Siyuan All rights reserved</li>
            <li>Design: Horatio</li>
            <li><a style="text-decoration:none;" href="https://coding.net/pages" >Hosted by Coding Pages</a></li>
        </ul>
    </div>
</footer>
    </div>

    <!-- After footer scripts -->
    <script type="text/javascript"
color="139,129,80" opacity='0.4' zIndex="-2" count="20" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"></script>

<!-- jQuery -->
<script src="/js/jquery.min.js"></script>

<!-- skel -->
<script src="/js/skel.min.js"></script>

<!-- Custom Code -->
<script src="/js/util.js"></script>

<!--[if lte IE 8]>
<script src="/js/ie/respond.min.js"></script>
<![endif]-->

<!-- Custom Code -->
<script src="/js/main.js"></script>

<!-- Gallery -->
<script src="//cdn.rawgit.com/noelboss/featherlight/1.3.5/release/featherlight.min.js" type="text/javascript" charset="utf-8"></script>

<!-- Disqus Comments -->



<!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax --><!-- hexo-inject:begin --><!-- hexo-inject:end -->

<!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
</body>

</html>